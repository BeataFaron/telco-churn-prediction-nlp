{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18858,"sourceType":"datasetVersion","datasetId":13996},{"sourceId":12257490,"sourceType":"datasetVersion","datasetId":7630515}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# üõ†Ô∏è How We Created Synthetic Customer Feedback Using GPT for Churn Prediction\n\n*Author: Beata Faron  \nDate: 2025-07-14*\n\nIn this notebook, we explain the process of generating **realistic customer feedback** for a Telco churn dataset using **GPT-based language models**.  \nThis synthetic data allows us to simulate realistic scenarios where companies have access to customer comments‚Äîwithout violating any privacy or relying on incomplete textual fields.\n\nWe focus on:\n- Generating feedback from structured data (e.g., churn status, contract type),\n- Using prompt engineering,\n- Applying lightweight heuristics to filter poor or repetitive answers.\n","metadata":{}},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport time","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\n## Step 0. Set up OpenAI Access\n\nTo generate synthetic customer feedback using GPT, you‚Äôll need access to the OpenAI API.\n\n#### Follow these steps:\n\n1. **Create an OpenAI account**\n   Visit: [https://platform.openai.com/signup](https://platform.openai.com/signup)\n   Sign up using your email or GitHub/Google account.\n\n2. **Navigate to the API section**\n   After logging in, go to: [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)\n\n3. **Generate a new secret API key**\n\n   * Click on `+ Create new secret key`\n   * Copy the generated token and store it **securely** ‚Äì you won‚Äôt be able to see it again later.\n\n     \n     \n\n4. **Install the OpenAI Python package** (if not already installed)\n","metadata":{}},{"cell_type":"code","source":" pip install openai","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"5. **Set your API key in your notebook or environment**","metadata":{}},{"cell_type":"code","source":"import openai\n     openai.api_key = \"your-secret-api-key\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 1. Preview of the Telco Dataset","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n# Show a few rows\ndf.sample(5, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:47:37.239742Z","iopub.execute_input":"2025-07-14T07:47:37.240095Z","iopub.status.idle":"2025-07-14T07:47:37.723635Z","shell.execute_reply.started":"2025-07-14T07:47:37.240051Z","shell.execute_reply":"2025-07-14T07:47:37.722528Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## Step 2. GPT Prompt Design\n\nWe designed a prompt that generates personalized feedback based on key customer attributes.  \nExample prompt (used with `text-davinci-003` or `gpt-3.5-turbo`):\n\n```\nYou are a customer of a telecom company. \nYour contract is {Contract}, you pay {MonthlyCharges}$ per month, and your internet service is {InternetService}. \nYou {Churned} from the company. \nPlease write a realistic reason (2-3 sentences) why you decided to leave or stay.\n```\n\nThis prompt was dynamically generated for each row in the dataset.\n","metadata":{}},{"cell_type":"code","source":"# Function to construct a GPT prompt from structured customer data\ndef create_prompt(row):\n    return (\n        f\"Write a realistic customer feedback based on this profile:\\n\"\n        f\"Churn: {row['Churn']}\\n\"\n        f\"Tenure: {row['tenure']} months\\n\"\n        f\"Contract type: {row['Contract']}\\n\"\n        f\"Monthly Charges: ${row['MonthlyCharges']}\\n\"\n        f\"Internet Service: {row['InternetService']}\\n\"\n        f\"Payment Method: {row['PaymentMethod']}\"\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## ‚ûú Generate feedback sample","metadata":{}},{"cell_type":"code","source":"# Initialize OpenAI client (use your own API key or secret manager)\nimport os\nfrom openai import OpenAI\n\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# Store generated feedback here\nfeedbacks = []\n\n# Loop over each customer row and generate GPT response\nfor idx, row in sample_df.iterrows():\n    prompt = create_prompt(row)\n    \n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=0.7,\n            max_tokens=150\n        )\n        feedback = response.choices[0].message.content.strip()\n    except Exception as e:\n        feedback = f\"ERROR: {str(e)}\"\n    \n    feedbacks.append(feedback)\n    time.sleep(1.5)  # Sleep to respect rate limits\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"| Parameter     | Description                                                 | Example Value                             | Effect                                     |\n| ------------- | ----------------------------------------------------------- | ----------------------------------------- | ------------------------------------------ |\n| `model`       | GPT model version to use                                    | `\"gpt-3.5-turbo\"`                         | Fast, cost-efficient, conversational       |\n| `messages`    | List of message objects simulating a chat (role + content)  | `[{{\"role\": \"user\", \"content\": prompt}}]` | Simulates a user asking a question         |\n| `temperature` | Controls randomness and creativity of output                | `0.2` to `1.0`                            | Higher = more variety, lower = more stable |\n| `max_tokens`  | Maximum length of the generated text (tokens ‚âà words √ó 1.3) | `150`                                     | Longer values = longer answers             |\n","metadata":{}},{"cell_type":"markdown","source":"| Temperature | Example Feedback                                                                   |\n| ----------- | ---------------------------------------------------------------------------------- |\n| `0.2`       | *\"I left because the bill increased without notice.\"*                              |\n| `0.7`       | *\"After months of hidden fees and poor customer service, I finally had enough.\"*   |\n| `0.95`      | *\"Boom! My Wi-Fi exploded and took my patience with it. Time to cut the cord!\"* üòÖ |\n","metadata":{}},{"cell_type":"markdown","source":"| max\\_tokens | Approximate Output                       |\n| ----------- | ---------------------------------------- |\n| `50`        | 1‚Äì2 short sentences                      |\n| `100`       | 2‚Äì4 medium sentences                     |\n| `150`       | Up to a paragraph (default in our setup) |\n","metadata":{}},{"cell_type":"markdown","source":"## ‚ûú Append","metadata":{}},{"cell_type":"code","source":"# Add both prompt and feedback to the sample dataframe\nsample_df[\"PromptInput\"] = sample_df.apply(create_prompt, axis=1)\nsample_df[\"CustomerFeedback\"] = feedbacks\n\n# Display results\nsample_df[[\"customerID\", \"PromptInput\", \"CustomerFeedback\"]].head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n##  Step 3. Quality Filtering Heuristics\n\nWe used a mix of simple, efficient heuristics to clean the generated feedback:\n- **Semantic similarity check** using embeddings to detect near-duplicates\n- **Regex filters** to remove overly generic or broken outputs\n- **Manual spot-checking** for the first batches\n\nThis ensured the final dataset was diverse and believable.\n","metadata":{}},{"cell_type":"markdown","source":"# Supporting Files","metadata":{}},{"cell_type":"markdown","source":"\n\n‚û°Ô∏è The final dataset is available here: [Telco Customer Churn + Realistic Customer Feedback](https://www.kaggle.com/datasets/beatafaron/telco-customer-churn-realistic-customer-feedback) <br>\n‚û°Ô∏è Modeling notebook (using this data): [Exploring Customer Churn & GPT-generated Feedback](https://www.kaggle.com/code/beatafaron/eda-customer-churn-gpt-generated-feedback)\n","metadata":{}},{"cell_type":"markdown","source":"# * Lesson learned\n Note: Later analysis showed that some GPT responses inadvertently reflected the churn label too directly. To reduce potential data leakage, we truncated feedback to remove overly revealing first phrases and introduced realistic noise. This is discussed in a follow-up notebook.\n\n ‚û°Ô∏è Real noise simulation: [Feedback Noise Simulation & Fallback Testing\n](https://www.kaggle.com/code/beatafaron/feedback-noise-simulation-fallback-testing)\n","metadata":{}}]}